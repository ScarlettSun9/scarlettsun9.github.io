<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Paper Review üìù - Retrieval-Augmented Generation for Large Language Models - A Survey | Miaomiao Song </title> <meta name="author" content="Miaomiao Song"> <meta name="description" content="Paper review for RAG in LLMs | Last revised 27 March 2024"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8C%B2&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://scarlettsun9.github.io/blog/2024/RAG-For-LLM-Survey/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Miaomiao</span> Song </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Paper Review üìù - Retrieval-Augmented Generation for Large Language Models - A Survey</h1> <p class="post-meta"> April 23, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a> ¬† ¬∑ ¬† <a href="/blog/tag/rag"> <i class="fa-solid fa-hashtag fa-sm"></i> RAG</a> ¬† <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> LLM</a> ¬† </p> </header> <article class="post-content"> <div id="markdown-content"> <blockquote> <p>[!TIP] The most important thing I learned from reading this paper is not the technical part of RAG for LLMs, but the best time to read a survey paper. The best practice to get to know a new branch of knowledge is not read survey papers at first (like me this time üò¢), but to fully understand several major / key / ‚Äúmilestone‚Äù papers first (which can be selected from the references), then come back to read the whole survey paper.</p> </blockquote> <hr> <p><em>The survey paper is already a summary. And this post is a summary of summary :D</em></p> <h2 id="rag-niche-research-stages-and-research-paradigms">RAG: Niche, Research Stages, and Research Paradigms</h2> <h3 id="niche-in-todays-research-of-rags-for-llms">Niche (in today‚Äôs research of RAGs for LLMs)</h3> <p>LLMs encounter challenges like hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. ‚û°Ô∏è RAG is a promising solution for it by incorporating knowledge from external databases, which is benefitial to enchance the accuracy and credibility of the generation, continuous knowledge updates and integration of domain-specific information.</p> <h3 id="research-stages">Research Stages</h3> <div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/20240423-1-480.webp 480w,/assets/img/20240423-1-800.webp 800w,/assets/img/20240423-1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/20240423-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Technology tree of RAG research </div> </div> <ul> <li>Early stage (mainly before the arrival of ChatGPT): foundational works focusing on enhancing language models by incorporating additional knowledge through Pre- Training Models (PTM).</li> <li>Inference stage: providing better information for LLMs to answer more com- plex and knowledge-intensive tasks during the inference</li> <li>Today: delving deeper and integrating more with the fine-tuning of LLMs</li> </ul> <h3 id="research-paradigms">Research Paradigms</h3> <div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/20240423-2-480.webp 480w,/assets/img/20240423-2-800.webp 800w,/assets/img/20240423-2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/20240423-2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> RAG research paradigms: Naive RAG, Advanced RAG and Modular RAG </div> </div> <p>The development of Advanced RAG and Modular RAG is a response to these specific shortcomings in Naive RAG.</p> <h4 id="naive-rag">Naive RAG</h4> <div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/20240423-3-480.webp 480w,/assets/img/20240423-3-800.webp 800w,/assets/img/20240423-3-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/20240423-3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Naive RAG: a representative instance of the RAG process applied to question answering </div> </div> <p>The process of this Naive RAG in question-answering task is similar to the <a href="www.example.org">original paper of RAG</a>, except for modifying the prompt (combination of query and retrieved chunks). However, the Naive RAG has notable drawbacks:</p> <ol> <li> <strong>Retrieval Challenges</strong>: The retrieval phase often struggles with precision and recall, leading to the selection of misaligned or irrelevant chunks, and the missing of crucial information.</li> <li> <strong>Generation Difficulties</strong>: issue of hallucination, irrelevance, toxicity, or bias in the outputs</li> <li> <strong>Augmentation Hurdles</strong>: Integrating retrieved information can result in disjointed or incoherent outputs, repetitive responses.</li> <li> <strong>Over-relyance</strong>: The generation models might overly rely on augmented information, leading to outputs that simply echo retrieved content without adding insightful or synthesized information.</li> </ol> <h4 id="advanced-rag">Advanced RAG</h4> <ul> <li>Target: enchance retreival quality</li> <li>Pre-retrieval process: optimizing the indexing structure and the original query <ul> <li>enhancing data granularity</li> <li>optimizing index structures</li> <li>adding metadata</li> <li>alignment optimization</li> <li>mixed retrieval</li> </ul> </li> <li>Post-retrieval process: <ul> <li>rerank chunks - Re-ranking the retrieved information to relocate the most relevant content to the edges of the prompt</li> <li>context compressing - selecting the essential information, emphasizing critical sections, and shortening the context to be processed</li> </ul> </li> </ul> <h4 id="modular-rag">Modular RAG</h4> <ul> <li>Modular RAG builds upon the foundational principles of Advanced and Naive RAG.</li> <li>New modules <ul> <li>search module: adapting to spe- cific scenarios &amp; enabling direct searches across various data sources like search engines, databases, and knowledge graphs</li> <li>fusion module: employing a multi-query strategy that expands user queries into diverse perspectives</li> <li>memory module: leveraging the LLM‚Äôs memory to guide retrieval &amp; creating an unbounded memory pool</li> <li>route module: navigating through diverse data sources &amp; selecting the optimal pathway for a query</li> <li>predict module: reducing redundancy and noise by generating context directly through the LLM</li> <li>task adapter: tailoring RAG to various downstream tasks &amp; automating prompt retrieval for zero-shot inputs &amp; creating task-specific retrievers through few-shot query generation</li> </ul> </li> <li>New patterns <ul> <li>allowing module substitution or reconfiguration to address specific challenges</li> </ul> </li> </ul> <h2 id="rag-vs-fine-tuning-vs-prompt-engineering">RAG vs. Fine-tuning vs. Prompt Engineering</h2> <div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/20240423-4-480.webp 480w,/assets/img/20240423-4-800.webp 800w,/assets/img/20240423-4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/20240423-4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> RAG vs. Fine-tuning vs. Prompt Engineering in the aspects of ‚ÄúExternal Knowledge Required‚Äù and ‚ÄúModel Adaption Required‚Äù </div> </div> <ul> <li> <p>RAG, fine-tuning and prompt engineering are all optimization methods for LLMs.</p> </li> <li>RAG <ul> <li>providing a model with a tailored textbook for information retrieval, ideal for <strong>precise information retrieval</strong> tasks</li> <li>excels in <strong>dynamic environments</strong> by offering real-time knowledge updates and effective utilization of external knowledge sources with <strong>high interpretability</strong> </li> <li>higher latency and ethical considerations regarding data retrieval</li> </ul> </li> <li>Fine-tuning <ul> <li>more static</li> <li>comparable to a student internalizing knowledge over time</li> <li>suitable for scenarios requiring replication of <strong>specific structures, styles, or formats</strong> </li> <li>requiring retraining for updates but enabling <strong>deep customization of the model‚Äôs behavior and style</strong> </li> <li>demanding significant computational resources for dataset preparation and training</li> <li>can reduce hallucinations, but may face challenges with unfamiliar data</li> <li><strong>LLMs struggle to learn new factual information through unsupervised fine- tuning.</strong></li> </ul> </li> <li>Prompt engineering <ul> <li>leveraging a model‚Äôs inherent capabilities with minimum necessity for external knowledge and model adaption</li> </ul> </li> </ul> <h2 id="the-r-of-rag---retrieval">The R of RAG - Retrieval</h2> <ul> <li>Retrieval Source <ul> <li>Data structure <ul> <li>unstructured data (e.g. text)</li> <li>semi-structured data (e.g. PDF (which contains text and table))</li> <li>structured data (e.g. knowledge graph)</li> <li>LLM-generated content</li> </ul> </li> <li>Retrieval gradularity <ul> <li>croase-grained vs. fine-grained</li> <li>Token ‚û°Ô∏è Phrase ‚û°Ô∏è Sentence ‚û°Ô∏è Proposition ‚û°Ô∏è Chunks ‚û°Ô∏è Document</li> <li>Special case: using proposition as retrieval unit</li> </ul> </li> </ul> </li> <li>Indexing optimization <ul> <li>Chunking Strategy (large chunk vs. small chunk - strike a balance between semantic completeness and context length)</li> <li>Metadata Attachments (page numbers, file names and even artificially constructed metadata like summary)</li> <li>Structural Index <ul> <li>Hierarchical index structure</li> <li>Knowledge Graph index</li> </ul> </li> </ul> </li> <li>Query optimization <ul> <li>Query Expansion <ul> <li>Multi-Query</li> <li>Sub-Query</li> <li>Chain-of-Verification(CoVe)</li> </ul> </li> <li>Query Transformation <ul> <li>Query rewrite</li> <li>LLM-modified query (use prompt engineering to let LLM generate a query based on the original query for subsequent retrieval)</li> </ul> </li> <li>Query Routing <ul> <li>Metadata Router/ Filter</li> <li>Semantic Router</li> </ul> </li> </ul> </li> <li>Embedding <ul> <li>Mix/hybrid Retrieval</li> <li>Fine-tuning Embedding Model</li> </ul> </li> <li>Adapter <ul> <li>designed to accommodate multiple downstream tasks or to enhance performance on specific tasks</li> </ul> </li> </ul> <h2 id="the-g-of-rag---generation">The G of RAG - Generation</h2> <ul> <li>Context Curation - further process the retrieved content <ul> <li>Reranking (reorders document chunks to highlight the most pertinent results first)</li> <li>Context Selection/Compression</li> </ul> </li> <li>LLM Fine-tuning / RLHF</li> </ul> <h2 id="the-a-of-rag---augmentation">The A of RAG - Augmentation</h2> <p>The standard practice often involves a singular (once) retrieval step followed by generation, which can lead to inefficiencies and sometimes is typically insufficient for complex problems demanding multi-step reasoning. So‚Ä¶</p> <div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/20240423-5-480.webp 480w,/assets/img/20240423-5-800.webp 800w,/assets/img/20240423-5-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/20240423-5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> three types of retrieval augmentation processes </div> </div> <ul> <li>Iterative Retrieval <ul> <li>Iterative retrieval is a process where the knowledge base is repeatedly searched based on the initial query and the text generated so far.</li> </ul> </li> <li>Recursive Retrieval <ul> <li>iteratively refining search queries based on the results obtained from previous searches</li> <li>aiming to enhance the search experience by gradu- ally converging on the most pertinent information through a feedback loop</li> <li>To address specific data scenarios, recursive retrieval and multi-hop retrieval techniques are utilized together</li> </ul> </li> <li>Adaptive Retrieval <ul> <li>enabling LLMs to actively determine the optimal moments and content for retrieval</li> </ul> </li> </ul> <h2 id="tasks--evaluation">Tasks &amp; Evaluation</h2> <ul> <li>Downstream tasks <ul> <li>QA</li> <li>Infor- mation Extraction (IE)</li> <li>dialogue generation</li> <li>code search</li> </ul> </li> <li>Evaluation Target <ul> <li>Historically: evaluated by downstream tasks criteria</li> <li>Now: evaluate the distinct characteristics of RAG models <ul> <li>Retrieval Quality</li> <li>Generation Quality</li> </ul> </li> </ul> </li> <li>Evaluation Aspects <ul> <li>Quality Scores <ul> <li>Context Relevance -&gt; Retrieval Quality</li> <li>Answer Faithfulness</li> <li>Answer Relevance</li> </ul> </li> <li>Required Abilities <ul> <li>Noise Robustness -&gt; Retrieval Quality</li> <li>Negative Rejection</li> <li>Information Integration</li> <li>Counterfactual Robustness</li> </ul> </li> </ul> </li> <li>Evaluation Benchmarks and Tools</li> </ul> <div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/20240423-6-480.webp 480w,/assets/img/20240423-6-800.webp 800w,/assets/img/20240423-6-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/20240423-6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <h2 id="future-prospects">Future Prospects</h2> <ol> <li>RAG vs Long Context. RAG still plays an irreplaceable role because a large amount of context at once will significantly impact its inference speed, and RAG-based generation can quickly locate the original references for LLMs to help users verify the generated an- swers, which is observable. Developing new RAG methods in the context of super-long contexts is one of the future research trends.</li> <li>RAG Robustness. ‚ÄúMisinformation can be worse than no information at all‚Äù.</li> <li>Hybrid Approaches = RAG + FT</li> <li>Scaling laws of RAG. While scaling laws are established for LLMs, their applicability to RAG remains uncertain.</li> <li>Production-Ready RAG. Customization, simplification, specialization.</li> <li>Multi-modal RAG. (image, audio, video, code)</li> </ol> <div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/20240423-7-480.webp 480w,/assets/img/20240423-7-800.webp 800w,/assets/img/20240423-7-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/20240423-7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Summary of RAG Ecosystem </div> </div> <h2 id="personal-comment">Personal Comment</h2> <p>Well I cannot give formal judgement to the survey quality because I am still a novice to RAG. My comment to the paper from the perspective of written language is that some sentences are too complicated, and too many repetitive expressions are used. However, flaws do not cover up strengths. The logic of the survey is clear enough for beginners. The illustrations are superb in my opinion, with forms of neat and pleasing simplicity and consice harmonic colors.</p> </div> </article> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"ScarlettSun9/scarlettsun9.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2024 Miaomiao Song. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>